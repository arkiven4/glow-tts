{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor, WavLMForXVector\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torchaudio\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained('microsoft/wavlm-base-plus-sv')\n",
    "model = WavLMForXVector.from_pretrained('microsoft/wavlm-base-plus-sv')\n",
    "\n",
    "def extract_wav(path, f_low, f_high):\n",
    "    sr, audio_data = wavfile.read(path)\n",
    "    \n",
    "    # Create a bandpass filter with a passband between f_low and f_high\n",
    "    nyquist_rate = 0.5 * sr\n",
    "    filter_order = 6\n",
    "    filter_cutoff = [f_low / nyquist_rate, f_high / nyquist_rate]\n",
    "    b, a = signal.butter(filter_order, filter_cutoff, btype='bandpass')\n",
    "\n",
    "    # Apply the bandpass filter to the audio data\n",
    "    filtered_audio = signal.filtfilt(b, a, audio_data)\n",
    "\n",
    "    # Normalize the audio data to the range [-1, 1]\n",
    "    #normalized_audio = filtered_audio / max(abs(filtered_audio))\n",
    "\n",
    "    return filtered_audio\n",
    "\n",
    "def extract_embedding(audio_data):\n",
    "    # audio files are decoded on the fly\n",
    "    audio = [audio_data]\n",
    "    inputs = feature_extractor(audio, padding=True, return_tensors=\"pt\", sampling_rate = 16000)\n",
    "    embeddings = model(**inputs).embeddings\n",
    "    #embeddings = torch.nn.functional.normalize(embeddings, dim=-1).cpu()\n",
    "    return embeddings[0]\n",
    "\n",
    "def calculate_score(embeddings1, embeddings2):    \n",
    "    # the resulting embeddings can be used for cosine similarity-based retrieval\n",
    "    cosine_sim = torch.nn.CosineSimilarity(dim=-1)\n",
    "    similarity = cosine_sim(embeddings1, embeddings2)\n",
    "    threshold = 0.86  # the optimal threshold is dataset-dependent\n",
    "    # if similarity < threshold:\n",
    "    #     print(\"Speakers are not the same!\")\n",
    "    return float(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load(\"Example/p233_001.wav\", sr=16000)\n",
    "embedding_data = extract_embedding(y)\n",
    "torch.save(embedding_data, f\"Example/p233_001.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load(\"Example/p233_006.wav\", sr=16000)\n",
    "embedding_data = extract_embedding(y)\n",
    "torch.save(embedding_data, f\"Example/p233_006.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOW = 50\n",
    "FHIGH = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "FLOW = 50\n",
    "FHIGH = 4000\n",
    "\n",
    "for index, row in df_sample.iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets_split\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        embedding_data = extract_embedding(extract_wav(sample_path, FLOW, FHIGH))\n",
    "        torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")\n",
    "    except:\n",
    "        print(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_unknown.iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets_split\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, FLOW, FHIGH))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_unknown.where(df_unknown[\"sample_compare\"] == \"Andreas Guntoro\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 50, 4000))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")\n",
    "\n",
    "for index, row in df_sample.where(df_sample[\"speaker\"] == \"Andreas Guntoro\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 50, 4000))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_unknown.where(df_unknown[\"sample_compare\"] == \"Asep Gunawan\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 300, 3500))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")\n",
    "\n",
    "for index, row in df_sample.where(df_sample[\"speaker\"] == \"Asep Gunawan\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 300, 3500))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_unknown.where(df_unknown[\"sample_compare\"] == \"Dadang\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 150, 4000))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")\n",
    "\n",
    "for index, row in df_sample.where(df_sample[\"speaker\"] == \"Dadang\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 50, 4000))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_unknown.where(df_unknown[\"sample_compare\"] == \"Nadya Nurul Anisa\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 150, 3500))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")\n",
    "\n",
    "for index, row in df_sample.where(df_sample[\"speaker\"] == \"Nadya Nurul Anisa\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 150, 3500))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_unknown.where(df_unknown[\"sample_compare\"] == \"Khairur Rizal\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 350, 3500))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")\n",
    "\n",
    "for index, row in df_sample.where(df_sample[\"speaker\"] == \"Khairur Rizal\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 350, 3500))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_unknown.where(df_unknown[\"sample_compare\"] == \"Ferlian Hady\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 150, 3500))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")\n",
    "\n",
    "for index, row in df_sample.where(df_sample[\"speaker\"] == \"Ferlian Hady\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 150, 3500))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_unknown.where(df_unknown[\"sample_compare\"] == \"Sony Setiadi\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 350, 3500))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")\n",
    "\n",
    "for index, row in df_sample.where(df_sample[\"speaker\"] == \"Sony Setiadi\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 350, 3500))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/unknown/Yana Mulyana/phone1_unknown2_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/unknown/Yana Mulyana/phone2_unknown1_2.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown1_3.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown1_4.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown1_5.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown1_6.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown1_7.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown1_8.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown1_9.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown2_1.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown2_10.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown2_2.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown2_3.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown2_4.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown2_5.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown2_6.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown2_7.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown2_8.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown2_9.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown1_1.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown1_2.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown1_3.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown1_4.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown1_5.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown1_6.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown1_7.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown1_8.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown1_9.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_1.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_10.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_11.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_12.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_13.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_14.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_16.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_17.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_18.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_2.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_3.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_4.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_5.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_6.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_7.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_8.wav\n",
      "datasets/unknown/Yana Mulyana/phone1_unknown2_9.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown1_1.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown1_10.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown1_11.wav\n",
      "datasets/unknown/Yana Mulyana/phone2_unknown1_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arkiven4/.local/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_unknown.where(df_unknown[\"sample_compare\"] == \"Yana Mulyana\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "    print(sample_path)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 150, 3500))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")\n",
    "\n",
    "for index, row in df_sample.where(df_sample[\"speaker\"] == \"Yana Mulyana\").dropna().iterrows():\n",
    "    sample_path = row['fullpath']\n",
    "    save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    embedding_data = extract_embedding(extract_wav(sample_path, 150, 3500))\n",
    "    torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in df_unknown.iterrows():\n",
    "#     sample_path = row['fullpath']\n",
    "#     save_path = row['fullpath'].replace(\"datasets\",\"embeddings\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "#     Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "#     print(sample_path)\n",
    "\n",
    "#     embedding_data = extract_embedding(extract_wav(sample_path))\n",
    "#     torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample = pd.read_csv(\"data_sample_telephone.csv\")\n",
    "# df_unknown = pd.read_csv(\"data_uknown_telephone.csv\")\n",
    "\n",
    "# for index, row in df_sample.iterrows():\n",
    "#     sample_path = row['fullpath']\n",
    "#     save_path = row['fullpath'].replace(\"datasets_telephone\",\"embeddings_telephone\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "#     Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "#     print(sample_path)\n",
    "\n",
    "#     embedding_data = extract_embedding(extract_wav(sample_path))\n",
    "#     torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")\n",
    "\n",
    "# for index, row in df_unknown.iterrows():\n",
    "#     sample_path = row['fullpath']\n",
    "#     save_path = row['fullpath'].replace(\"datasets_telephone\",\"embeddings_telephone\").replace(f\"{row['filename']}.wav\",\"\")\n",
    "#     Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "#     print(sample_path)\n",
    "\n",
    "#     embedding_data = extract_embedding(extract_wav(sample_path))\n",
    "#     torch.save(embedding_data, f\"{save_path}{row['filename']}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
