{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from text import text_to_sequence, cmudict\n",
    "from text.symbols import symbols, _letters, _pad, _punctuation\n",
    "from text import cleaners\n",
    "import commons\n",
    "import attentions\n",
    "import modules\n",
    "import models\n",
    "import model_vad\n",
    "import utils\n",
    "import random\n",
    "import os\n",
    "from unidecode import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ʃʧʦ↓↑ ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㄲㄸㅃㅆㅉㅏㅓㅗㅜㅡㅣㅐㅔ '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_new = 'AEINOQUabdefghijkmnoprstuvwyzʃʧʦ↓↑ ' + 'ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㄲㄸㅃㅆㅉㅏㅓㅗㅜㅡㅣㅐㅔ '\n",
    "_newletters = [s for s in letter_new if s not in _letters]\n",
    "\"\".join(_newletters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ko↑no je↑ʃii↓yakude sU↑tei↓mosuwa, e↑mii↓ʃooni no↑mine↓eto sa↑reta ko↑to↓mo a↓ru.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaners.japanese_cleaners(\"このジェシー役でステイモスは、エミー賞にノミネートされたこともある。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ㄱㅣㅔㅅㅗㄱㅎㅐㅅㅓ ㅈㅓㄹㅓㅎㄱㅔ ㅇㅓㄱㅈㅣ ㅈㅜㅈㅏㅇㅇㅡㄹ ㅎㅏㄱㅗ ㅇㅣㅆㅇㅡㄴㅣ ㅈㅓ ㅁㅗㅇㅣㅏㅇㅇㅣㅈㅣ.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaners.korean_cleaners(\"계속해서 저렇게 억지 주장을 하고 있으니 저 모양이지.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"ㄱㅣㅔㅅㅗㄱㅎㅐㅅㅓ ㅈㅓㄹㅓㅎㄱㅔ ㅇㅓㄱㅈㅣ ㅈㅜㅈㅏㅇㅇㅡㄹ ㅎㅏㄱㅗ ㅇㅣㅆㅇㅡㄴㅣ ㅈㅓ ㅁㅗㅇㅣㅏㅇㅇㅣㅈㅣ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"계속해서 저렇게 억지 주장을 하고 있으니 저 모양이지.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Speaker Embed Linear Norm\n",
      "Use Multilanguage Cathegorical\n"
     ]
    }
   ],
   "source": [
    "hps = utils.get_hparams_from_file(\"configs/base_blank_emo_lang.json\")\n",
    "\n",
    "generator = models.FlowGenerator(\n",
    "        n_vocab=len(symbols) + getattr(hps.data, \"add_blank\", False),\n",
    "        out_channels=hps.data.n_mel_channels,\n",
    "        n_lang=hps.data.n_lang,\n",
    "        # n_speakers=hps.data.n_speakers,\n",
    "        **hps.model\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = hps.train.warm_start_checkpoint\n",
    "model = generator\n",
    "ignore_layers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm starting model from checkpoint 'logs/base_blank_emo_lang_onlyintextencoder/G_143.pth'\n"
     ]
    }
   ],
   "source": [
    "assert os.path.isfile(checkpoint_path)\n",
    "print(\"Warm starting model from checkpoint '{}'\".format(checkpoint_path))\n",
    "checkpoint_dict = torch.load(checkpoint_path, map_location='cpu')\n",
    "model_dict = checkpoint_dict['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weight(original_tensor, target_size):\n",
    "    differences = [target_size[i] - original_tensor.size(i) for i in range(len(target_size))]\n",
    "    for i, diff in enumerate(differences):\n",
    "        if diff > 0:\n",
    "            new_dims = list(original_tensor.size())\n",
    "            new_dims[i] = diff\n",
    "            rand_weight = torch.randn(*new_dims)\n",
    "            original_tensor = torch.cat([original_tensor, rand_weight], dim=i)\n",
    "        elif diff < 0:\n",
    "            slices = []\n",
    "            for j in range(len(target_size)):\n",
    "                if j == i:\n",
    "                    slices.append(slice(0, original_tensor.size(j) + diff))\n",
    "                else:\n",
    "                    slices.append(slice(0, original_tensor.size(j)))\n",
    "            slices[i] = slice(0, target_size[i])\n",
    "            original_tensor = original_tensor[slices]\n",
    "\n",
    "    return original_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatched_layers = []\n",
    "for key, value in model_dict.items(): # model_dict warmstart weight\n",
    "    if hasattr(model, 'module'): # model is current model\n",
    "        if key in model.module.state_dict() and value.size() != model.module.state_dict()[key].size():\n",
    "            try:\n",
    "                model_dict[key] = transfer_weight(model_dict[key], model.module.state_dict()[key].size())\n",
    "            except:\n",
    "                mismatched_layers.append(key)\n",
    "    else:\n",
    "        if key in model.state_dict() and value.size() != model.state_dict()[key].size():\n",
    "            try:\n",
    "                model_dict[key] = transfer_weight(model_dict[key], model.state_dict()[key].size())\n",
    "            except:\n",
    "                mismatched_layers.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([390, 390, 5])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[198, 192, 5]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dims = list(original_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_weight = torch.randn(*new_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 6, 0]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([198, 198, 5])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 192, 5])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[192, 192, 5, 6]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 192, 5, 6])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor_to_match(original_tensor, target_size):\n",
    "    differences = [target_size[i] - original_tensor.size(i) for i in range(len(target_size))]\n",
    "\n",
    "    # Pad along each dimension\n",
    "    for i, diff in enumerate(differences):\n",
    "        if diff > 0:\n",
    "            new_dims = list(original_tensor.size())\n",
    "            new_dims.append(diff)\n",
    "            rand_weight = torch.randn(*new_dims)\n",
    "            original_tensor = torch.cat([original_tensor, rand_weight], dim=i)\n",
    "        elif diff < 0:\n",
    "            slices = [slice(0, original_tensor.size(j)) for j in range(len(target_size))]\n",
    "            slices[i] = slice(0, target_size[i])\n",
    "            original_tensor = original_tensor[slices]\n",
    "\n",
    "    return original_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 3 and 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pad_tensor_to_match(model_dict[key], model\u001b[39m.\u001b[39;49mstate_dict()[key]\u001b[39m.\u001b[39;49msize())\n",
      "Cell \u001b[0;32mIn[117], line 10\u001b[0m, in \u001b[0;36mpad_tensor_to_match\u001b[0;34m(original_tensor, target_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m     new_dims\u001b[39m.\u001b[39mappend(diff)\n\u001b[1;32m      9\u001b[0m     rand_weight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m*\u001b[39mnew_dims)\n\u001b[0;32m---> 10\u001b[0m     original_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([original_tensor, rand_weight], dim\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m     11\u001b[0m \u001b[39melif\u001b[39;00m diff \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     12\u001b[0m     slices \u001b[39m=\u001b[39m [\u001b[39mslice\u001b[39m(\u001b[39m0\u001b[39m, original_tensor\u001b[39m.\u001b[39msize(j)) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(target_size))]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 3 and 4"
     ]
    }
   ],
   "source": [
    "pad_tensor_to_match(model_dict[key], model.state_dict()[key].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    size_diff = [max(0, new_size[i] - original_tensor.size(i)) for i in range(len(original_tensor.size()))]\n",
    "\n",
    "    # Create new tensor with random values\n",
    "    new_tensor = torch.randn(*new_size)\n",
    "\n",
    "    # Index to slice the original tensor based on its dimensions\n",
    "    slices = [slice(0, original_tensor.size(i)) for i in range(len(original_tensor.size()))]\n",
    "\n",
    "    # Update slices based on the size difference\n",
    "    for i in range(len(size_diff)):\n",
    "        slices[i] = slice(0, original_tensor.size(i))\n",
    "\n",
    "    # Copy values from the original tensor to the corresponding slice in the new tensor\n",
    "    new_tensor[slices] = original_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([198])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()[key].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict[key].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([198, 2, 5])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict[key][:,0:2,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()[key].size()[0] - value.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict[key].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mstate_dict()[key]\u001b[39m.\u001b[39;49mweight\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "model.state_dict()[key].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[key] = torch.cat([model_dict[key], new_row], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = torch.randn(model_dict[key].size()[-3], difference_1, model_dict[key].size()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([198, 6, 5])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[key] = torch.cat([model_dict[key], new_row], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([198, 198, 5])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict[key].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 198, 5])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original tensor size\n",
    "original_size = (192, 192, 5)\n",
    "\n",
    "# Desired size for the new tensor\n",
    "new_size = (198, 198, 5)\n",
    "\n",
    "# Calculate the number of new rows to add\n",
    "num_new_rows = new_size[0] - original_size[0]\n",
    "\n",
    "# Assuming emb_g is the original tensor\n",
    "emb_g = torch.rand(original_size)\n",
    "\n",
    "# Create new rows with random values\n",
    "new_rows = torch.randn(num_new_rows, original_size[1], original_size[2])\n",
    "\n",
    "# Concatenate the original tensor and new rows along the first dimension\n",
    "new_tensor = torch.cat([emb_g, new_rows], dim=0)\n",
    "\n",
    "# Check the size of the new tensor\n",
    "print(new_tensor.size())  # Output: torch.Size([198, 192, 5]) due to concatenation along the first dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 6, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Expected size 198 but got size 6 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mcat([model\u001b[39m.\u001b[39;49mstate_dict()[key], new_row], axis\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 198 but got size 6 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "torch.cat([model.state_dict()[key], new_row], axis=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "mismatched_layers = []\n",
    "for key, value in model_dict.items():\n",
    "    if hasattr(model, 'module'):\n",
    "        if key in model.module.state_dict() and value.size() != model.module.state_dict()[key].size():\n",
    "        mismatched_layers.append(key)\n",
    "    else:\n",
    "        if key in model.state_dict() and value.size() != model.state_dict()[key].size():\n",
    "        mismatched_layers.append(key)\n",
    "        \n",
    "print(mismatched_layers)\n",
    "\n",
    "ignore_layers = ignore_layers + mismatched_layers\n",
    "if len(ignore_layers) > 0:\n",
    "    model_dict = {k: v for k, v in model_dict.items()\n",
    "                    if k not in ignore_layers}\n",
    "    if hasattr(model, 'module'):\n",
    "        dummy_dict = model.module.state_dict()\n",
    "        dummy_dict.update(model_dict)\n",
    "    else:\n",
    "        dummy_dict = model.state_dict()\n",
    "        dummy_dict.update(model_dict)\n",
    "    model_dict = dummy_dict\n",
    "\n",
    "if hasattr(model, 'module'):\n",
    "    model.module.load_state_dict(model_dict, strict=False)\n",
    "else:\n",
    "    model.load_state_dict(model_dict, strict=False)\n",
    "return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = utils.warm_start_model(\n",
    "            hps.train.warm_start_checkpoint, generator, hps.train.ignored_layer\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(\"filelists/combine_audio_sid_text_test_filelist.txt\", \"r\") as txt_file:\n",
    "    lines = txt_file.readlines()\n",
    "    for line in lines:\n",
    "        audiopath = line.split(\"|\")[0]\n",
    "        if not os.path.isfile(audiopath):\n",
    "            print(audiopath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text import text_to_sequence, cmudict\n",
    "from text import cleaners\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_stn = \"Hello my name is Pras\"\n",
    "tst_stn = \"周末的我，只忙着陪你。\"\n",
    "\n",
    "tst_stn = \" \" + tst_stn.strip() + \" \"\n",
    "text_norm = text_to_sequence(tst_stn.strip(), ['basic_cleaners'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_to_sequence(tst_stn.strip(), ['universal_cleaners']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_to_sequence(unidecode(tst_stn).strip(), ['basic_cleaners']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Zhou Mo De Wo ,Zhi Mang Zhao Pei Ni .  '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unidecode(tst_stn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xi ndemoraetanarananiyoridesu'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unidecode(\"喜んでもらえたならなによりです\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = english_cleaners(tst_stn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_text(text, cleaner_names):\n",
    "  for name in cleaner_names:\n",
    "    cleaner = getattr(cleaners, name)\n",
    "    if not cleaner:\n",
    "      raise Exception('Unknown cleaner: %s' % name)\n",
    "    text = cleaner(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60,\n",
       " 52,\n",
       " 11,\n",
       " 61,\n",
       " 46,\n",
       " 11,\n",
       " 45,\n",
       " 58,\n",
       " 38,\n",
       " 51,\n",
       " 11,\n",
       " 39,\n",
       " 42,\n",
       " 46,\n",
       " 11,\n",
       " 47,\n",
       " 46,\n",
       " 51,\n",
       " 44,\n",
       " 11,\n",
       " 45,\n",
       " 58,\n",
       " 38,\n",
       " 51,\n",
       " 11,\n",
       " 62,\n",
       " 46,\n",
       " 51,\n",
       " 44,\n",
       " 11,\n",
       " 51,\n",
       " 46,\n",
       " 11,\n",
       " 7,\n",
       " 11]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
