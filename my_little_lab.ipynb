{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"|\"\n",
    "filepaths_and_text = []\n",
    "with open(\"filelists/newcombine_train_filelist.txt.cleaned\", encoding='utf-8') as f:\n",
    "    filepaths_and_text += [line.strip() for line in f if int(line.strip().split(split)[1]) == 0 or int(line.strip().split(split)[1]) == 2]\n",
    "\n",
    "with open(\"filelists/newcombine_test_filelist.txt.cleaned\", encoding='utf-8') as f:\n",
    "    filepaths_and_text += [line.strip() for line in f if int(line.strip().split(split)[1]) == 0 or int(line.strip().split(split)[1]) == 2]\n",
    "\n",
    "with open(\"filelists/newcombine_val_filelist.txt.cleaned\", encoding='utf-8') as f:\n",
    "    filepaths_and_text += [line.strip() for line in f if int(line.strip().split(split)[1]) == 0 or int(line.strip().split(split)[1]) == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths_and_text_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "perSample = 10\n",
    "emotion_folders = os.listdir(\"Database/VIBID/wavs\") \n",
    "for emotion_folder in emotion_folders:\n",
    "    if emotion_folder != 'Natural':\n",
    "        isComplete = False\n",
    "        filelist_temp = []\n",
    "        while isComplete == False:\n",
    "            random_file = random.choice(os.listdir(f\"Database/VIBID/wavs/{emotion_folder}\"))\n",
    "            if random_file not in filelist_temp:\n",
    "                count_fyat = sum([1 for elem in filelist_temp if elem.split(\"_\")[1] == 'fyat'])\n",
    "                count_mdpa = sum([1 for elem in filelist_temp if elem.split(\"_\")[1] == 'mdpa'])\n",
    "                if count_fyat < perSample and random_file.split(\"_\")[1] == 'fyat':\n",
    "                    filelist_temp.append(random_file)\n",
    "\n",
    "                if count_mdpa < perSample and random_file.split(\"_\")[1] == 'mdpa':\n",
    "                    filelist_temp.append(random_file)\n",
    "                    \n",
    "                if count_fyat == perSample and count_mdpa == perSample:\n",
    "                    for line in filepaths_and_text:\n",
    "                        metadata = line.split(\"|\")\n",
    "                        if int(metadata[1]) == 2:\n",
    "                            for random_file in filelist_temp:\n",
    "                                if metadata[0] == f\"/run/media/viblab/Markov2/Pras/Thesis/Database/VIBID/wavs/{emotion_folder}/{random_file}\":\n",
    "                                    filepaths_and_text_test.append(line)\n",
    "                                    filepaths_and_text.remove(line)\n",
    "                    isComplete = True\n",
    "    elif emotion_folder == 'Natural':\n",
    "        isComplete = False\n",
    "        filelist_temp = []\n",
    "        while isComplete == False:\n",
    "            random_file = random.choice(os.listdir(f\"Database/VIBID/wavs/{emotion_folder}\"))\n",
    "            if random_file not in filelist_temp:\n",
    "                count_fyat = sum([1 for elem in filelist_temp if elem.split(\"_\")[1] == 'fena'])\n",
    "                count_mdpa = sum([1 for elem in filelist_temp if elem.split(\"_\")[1] == 'mmht'])\n",
    "                if count_fyat < perSample and random_file.split(\"_\")[1] == 'fena':\n",
    "                    filelist_temp.append(random_file)\n",
    "\n",
    "                if count_mdpa < perSample and random_file.split(\"_\")[1] == 'mmht':\n",
    "                    filelist_temp.append(random_file)\n",
    "                    \n",
    "                if count_fyat == perSample and count_mdpa == perSample:\n",
    "                    for line in filepaths_and_text:\n",
    "                        metadata = line.split(\"|\")\n",
    "                        if int(metadata[1]) == 2:\n",
    "                            for random_file in filelist_temp:\n",
    "                                if metadata[0] == f\"/run/media/viblab/Markov2/Pras/Thesis/Database/VIBID/wavs/{emotion_folder}/{random_file}\":\n",
    "                                    filepaths_and_text_test.append(line)\n",
    "                                    filepaths_and_text.remove(line)\n",
    "                    isComplete = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filepaths_and_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_folders = os.listdir(\"Database/ESD/wavs/0011\") \n",
    "for speaker in [\"0011\", \"0012\", \"0013\", \"0014\", \"0015\", \"0016\", \"0017\", \"0018\"]:\n",
    "    for emotion_folder in emotion_folders:\n",
    "        random_files = random.choices(os.listdir(f\"Database/ESD/wavs/{speaker}/{emotion_folder}\"), k=3)\n",
    "        for line in filepaths_and_text:\n",
    "            metadata = line.split(\"|\")\n",
    "            if int(metadata[1]) == 0:\n",
    "                for random_file in random_files:\n",
    "                    if metadata[0] == f\"/run/media/viblab/Markov2/Pras/Thesis/Database/ESD/wavs/{speaker}/{emotion_folder}/{random_file}\":\n",
    "                        try:\n",
    "                            filepaths_and_text.remove(line)\n",
    "                            filepaths_and_text_test.append(line)\n",
    "                        except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths_and_text_val = filepaths_and_text[-150:]\n",
    "filepaths_and_text_train = filepaths_and_text[0:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('filelists/paper_test_filelist.txt', 'w') as f:\n",
    "    for line in filepaths_and_text_test:\n",
    "        f.write(f\"{line}\\n\")\n",
    "\n",
    "with open('filelists/paper_train_filelist.txt', 'w') as f:\n",
    "    for line in filepaths_and_text_train:\n",
    "        f.write(f\"{line}\\n\")\n",
    "\n",
    "with open('filelists/paper_val_filelist.txt', 'w') as f:\n",
    "    for line in filepaths_and_text_val:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/run/media/viblab/Markov2/Pras/Thesis/Database/ESD/wavs/0013/Sad/0013_001343.wav|0|he is old fashioned but he is the best of men.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0012_000851.wav',\n",
       " '0012_000914.wav',\n",
       " '0012_000832.wav',\n",
       " '0012_001047.wav',\n",
       " '0012_000783.wav',\n",
       " '0012_000929.wav',\n",
       " '0012_001047.wav',\n",
       " '0012_000802.wav',\n",
       " '0012_000991.wav',\n",
       " '0012_000790.wav']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filepaths_and_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Angry', 'Happy', 'Neutral', 'Sad', 'Surprise']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/media/viblab/Markov2/Pras/Thesis/TryMyOwn/glow-tts/.env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from text import text_to_sequence, cmudict\n",
    "from text.symbols import symbols, _letters, _pad, _punctuation\n",
    "from text import cleaners\n",
    "import commons\n",
    "import attentions\n",
    "import modules\n",
    "import models\n",
    "import model_vad\n",
    "import utils\n",
    "import random\n",
    "import os\n",
    "from unidecode import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ʃʧʦ↓↑ ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㄲㄸㅃㅆㅉㅏㅓㅗㅜㅡㅣㅐㅔ '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_new = 'AEINOQUabdefghijkmnoprstuvwyzʃʧʦ↓↑ ' + 'ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㄲㄸㅃㅆㅉㅏㅓㅗㅜㅡㅣㅐㅔ '\n",
    "_newletters = [s for s in letter_new if s not in _letters]\n",
    "\"\".join(_newletters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Mecab_load() in mecab.cpp: Cannot open /run/media/viblab/Markov2/Pras/Thesis/TryMyOwn/glow-tts/.env/lib/python3.8/site-packages/pyopenjtalk/open_jtalk_dic_utf_8-1.11.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to initalize Mecab",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cleaners\u001b[39m.\u001b[39;49mjapanese_cleaners(\u001b[39m\"\u001b[39;49m\u001b[39mこのジェシー役でステイモスは、エミー賞にノミネートされたこともある。\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/run/media/viblab/Markov2/Pras/Thesis/TryMyOwn/glow-tts/text/cleaners.py:101\u001b[0m, in \u001b[0;36mjapanese_cleaners\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjapanese_cleaners\u001b[39m(text):\n\u001b[0;32m--> 101\u001b[0m     text \u001b[39m=\u001b[39m japanese_to_romaji_with_accent(text)\n\u001b[1;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m re\u001b[39m.\u001b[39mmatch(\u001b[39m'\u001b[39m\u001b[39m[A-Za-z]\u001b[39m\u001b[39m'\u001b[39m, text[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]):\n\u001b[1;32m    103\u001b[0m         text \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m/run/media/viblab/Markov2/Pras/Thesis/TryMyOwn/glow-tts/text/japanese.py:84\u001b[0m, in \u001b[0;36mjapanese_to_romaji_with_accent\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m text \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     83\u001b[0m     text \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 84\u001b[0m labels \u001b[39m=\u001b[39m pyopenjtalk\u001b[39m.\u001b[39;49mextract_fullcontext(sentence)\n\u001b[1;32m     85\u001b[0m \u001b[39mfor\u001b[39;00m n, label \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(labels):\n\u001b[1;32m     86\u001b[0m     phoneme \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m-([^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m+]*)\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m, label)\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/run/media/viblab/Markov2/Pras/Thesis/TryMyOwn/glow-tts/.env/lib/python3.8/site-packages/pyopenjtalk/__init__.py:147\u001b[0m, in \u001b[0;36mextract_fullcontext\u001b[0;34m(text, run_marine)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_fullcontext\u001b[39m(text, run_marine\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    135\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Extract full-context labels from text\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \n\u001b[1;32m    137\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m        list: List of full-context labels\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     njd_features \u001b[39m=\u001b[39m run_frontend(text)\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m run_marine:\n\u001b[1;32m    149\u001b[0m         njd_features \u001b[39m=\u001b[39m estimate_accent(njd_features)\n",
      "File \u001b[0;32m/run/media/viblab/Markov2/Pras/Thesis/TryMyOwn/glow-tts/.env/lib/python3.8/site-packages/pyopenjtalk/__init__.py:209\u001b[0m, in \u001b[0;36mrun_frontend\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mif\u001b[39;00m _global_jtalk \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     _lazy_init()\n\u001b[0;32m--> 209\u001b[0m     _global_jtalk \u001b[39m=\u001b[39m OpenJTalk(dn_mecab\u001b[39m=\u001b[39;49mOPEN_JTALK_DICT_DIR)\n\u001b[1;32m    210\u001b[0m \u001b[39mreturn\u001b[39;00m _global_jtalk\u001b[39m.\u001b[39mrun_frontend(text)\n",
      "File \u001b[0;32mpyopenjtalk/openjtalk.pyx:142\u001b[0m, in \u001b[0;36mpyopenjtalk.openjtalk.OpenJTalk.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to initalize Mecab"
     ]
    }
   ],
   "source": [
    "cleaners.japanese_cleaners(\"このジェシー役でステイモスは、エミー賞にノミネートされたこともある。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ㄱㅣㅔㅅㅗㄱㅎㅐㅅㅓ ㅈㅓㄹㅓㅎㄱㅔ ㅇㅓㄱㅈㅣ ㅈㅜㅈㅏㅇㅇㅡㄹ ㅎㅏㄱㅗ ㅇㅣㅆㅇㅡㄴㅣ ㅈㅓ ㅁㅗㅇㅣㅏㅇㅇㅣㅈㅣ.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaners.korean_cleaners(\"계속해서 저렇게 억지 주장을 하고 있으니 저 모양이지.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"ㄱㅣㅔㅅㅗㄱㅎㅐㅅㅓ ㅈㅓㄹㅓㅎㄱㅔ ㅇㅓㄱㅈㅣ ㅈㅜㅈㅏㅇㅇㅡㄹ ㅎㅏㄱㅗ ㅇㅣㅆㅇㅡㄴㅣ ㅈㅓ ㅁㅗㅇㅣㅏㅇㅇㅣㅈㅣ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"계속해서 저렇게 억지 주장을 하고 있으니 저 모양이지.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Speaker Embed Linear Norm\n",
      "Use Multilanguage Cathegorical\n"
     ]
    }
   ],
   "source": [
    "hps = utils.get_hparams_from_file(\"configs/base_blank_emo_lang.json\")\n",
    "\n",
    "generator = models.FlowGenerator(\n",
    "        n_vocab=len(symbols) + getattr(hps.data, \"add_blank\", False),\n",
    "        out_channels=hps.data.n_mel_channels,\n",
    "        n_lang=hps.data.n_lang,\n",
    "        # n_speakers=hps.data.n_speakers,\n",
    "        **hps.model\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = hps.train.warm_start_checkpoint\n",
    "model = generator\n",
    "ignore_layers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm starting model from checkpoint 'logs/base_blank_emo_lang_onlyintextencoder/G_143.pth'\n"
     ]
    }
   ],
   "source": [
    "assert os.path.isfile(checkpoint_path)\n",
    "print(\"Warm starting model from checkpoint '{}'\".format(checkpoint_path))\n",
    "checkpoint_dict = torch.load(checkpoint_path, map_location='cpu')\n",
    "model_dict = checkpoint_dict['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weight(original_tensor, target_size):\n",
    "    differences = [target_size[i] - original_tensor.size(i) for i in range(len(target_size))]\n",
    "    for i, diff in enumerate(differences):\n",
    "        if diff > 0:\n",
    "            new_dims = list(original_tensor.size())\n",
    "            new_dims[i] = diff\n",
    "            rand_weight = torch.randn(*new_dims)\n",
    "            original_tensor = torch.cat([original_tensor, rand_weight], dim=i)\n",
    "        elif diff < 0:\n",
    "            slices = []\n",
    "            for j in range(len(target_size)):\n",
    "                if j == i:\n",
    "                    slices.append(slice(0, original_tensor.size(j) + diff))\n",
    "                else:\n",
    "                    slices.append(slice(0, original_tensor.size(j)))\n",
    "            slices[i] = slice(0, target_size[i])\n",
    "            original_tensor = original_tensor[slices]\n",
    "\n",
    "    return original_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatched_layers = []\n",
    "for key, value in model_dict.items(): # model_dict warmstart weight\n",
    "    if hasattr(model, 'module'): # model is current model\n",
    "        if key in model.module.state_dict() and value.size() != model.module.state_dict()[key].size():\n",
    "            try:\n",
    "                model_dict[key] = transfer_weight(model_dict[key], model.module.state_dict()[key].size())\n",
    "            except:\n",
    "                mismatched_layers.append(key)\n",
    "    else:\n",
    "        if key in model.state_dict() and value.size() != model.state_dict()[key].size():\n",
    "            try:\n",
    "                model_dict[key] = transfer_weight(model_dict[key], model.state_dict()[key].size())\n",
    "            except:\n",
    "                mismatched_layers.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([390, 390, 5])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[198, 192, 5]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dims = list(original_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_weight = torch.randn(*new_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 6, 0]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([198, 198, 5])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 192, 5])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[192, 192, 5, 6]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 192, 5, 6])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor_to_match(original_tensor, target_size):\n",
    "    differences = [target_size[i] - original_tensor.size(i) for i in range(len(target_size))]\n",
    "\n",
    "    # Pad along each dimension\n",
    "    for i, diff in enumerate(differences):\n",
    "        if diff > 0:\n",
    "            new_dims = list(original_tensor.size())\n",
    "            new_dims.append(diff)\n",
    "            rand_weight = torch.randn(*new_dims)\n",
    "            original_tensor = torch.cat([original_tensor, rand_weight], dim=i)\n",
    "        elif diff < 0:\n",
    "            slices = [slice(0, original_tensor.size(j)) for j in range(len(target_size))]\n",
    "            slices[i] = slice(0, target_size[i])\n",
    "            original_tensor = original_tensor[slices]\n",
    "\n",
    "    return original_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 3 and 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pad_tensor_to_match(model_dict[key], model\u001b[39m.\u001b[39;49mstate_dict()[key]\u001b[39m.\u001b[39;49msize())\n",
      "Cell \u001b[0;32mIn[117], line 10\u001b[0m, in \u001b[0;36mpad_tensor_to_match\u001b[0;34m(original_tensor, target_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m     new_dims\u001b[39m.\u001b[39mappend(diff)\n\u001b[1;32m      9\u001b[0m     rand_weight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m*\u001b[39mnew_dims)\n\u001b[0;32m---> 10\u001b[0m     original_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([original_tensor, rand_weight], dim\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m     11\u001b[0m \u001b[39melif\u001b[39;00m diff \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     12\u001b[0m     slices \u001b[39m=\u001b[39m [\u001b[39mslice\u001b[39m(\u001b[39m0\u001b[39m, original_tensor\u001b[39m.\u001b[39msize(j)) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(target_size))]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 3 and 4"
     ]
    }
   ],
   "source": [
    "pad_tensor_to_match(model_dict[key], model.state_dict()[key].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    size_diff = [max(0, new_size[i] - original_tensor.size(i)) for i in range(len(original_tensor.size()))]\n",
    "\n",
    "    # Create new tensor with random values\n",
    "    new_tensor = torch.randn(*new_size)\n",
    "\n",
    "    # Index to slice the original tensor based on its dimensions\n",
    "    slices = [slice(0, original_tensor.size(i)) for i in range(len(original_tensor.size()))]\n",
    "\n",
    "    # Update slices based on the size difference\n",
    "    for i in range(len(size_diff)):\n",
    "        slices[i] = slice(0, original_tensor.size(i))\n",
    "\n",
    "    # Copy values from the original tensor to the corresponding slice in the new tensor\n",
    "    new_tensor[slices] = original_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([198])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()[key].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict[key].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([198, 2, 5])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict[key][:,0:2,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()[key].size()[0] - value.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict[key].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mstate_dict()[key]\u001b[39m.\u001b[39;49mweight\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "model.state_dict()[key].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[key] = torch.cat([model_dict[key], new_row], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = torch.randn(model_dict[key].size()[-3], difference_1, model_dict[key].size()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([198, 6, 5])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[key] = torch.cat([model_dict[key], new_row], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([198, 198, 5])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict[key].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 198, 5])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original tensor size\n",
    "original_size = (192, 192, 5)\n",
    "\n",
    "# Desired size for the new tensor\n",
    "new_size = (198, 198, 5)\n",
    "\n",
    "# Calculate the number of new rows to add\n",
    "num_new_rows = new_size[0] - original_size[0]\n",
    "\n",
    "# Assuming emb_g is the original tensor\n",
    "emb_g = torch.rand(original_size)\n",
    "\n",
    "# Create new rows with random values\n",
    "new_rows = torch.randn(num_new_rows, original_size[1], original_size[2])\n",
    "\n",
    "# Concatenate the original tensor and new rows along the first dimension\n",
    "new_tensor = torch.cat([emb_g, new_rows], dim=0)\n",
    "\n",
    "# Check the size of the new tensor\n",
    "print(new_tensor.size())  # Output: torch.Size([198, 192, 5]) due to concatenation along the first dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 6, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Expected size 198 but got size 6 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mcat([model\u001b[39m.\u001b[39;49mstate_dict()[key], new_row], axis\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 198 but got size 6 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "torch.cat([model.state_dict()[key], new_row], axis=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "mismatched_layers = []\n",
    "for key, value in model_dict.items():\n",
    "    if hasattr(model, 'module'):\n",
    "        if key in model.module.state_dict() and value.size() != model.module.state_dict()[key].size():\n",
    "        mismatched_layers.append(key)\n",
    "    else:\n",
    "        if key in model.state_dict() and value.size() != model.state_dict()[key].size():\n",
    "        mismatched_layers.append(key)\n",
    "        \n",
    "print(mismatched_layers)\n",
    "\n",
    "ignore_layers = ignore_layers + mismatched_layers\n",
    "if len(ignore_layers) > 0:\n",
    "    model_dict = {k: v for k, v in model_dict.items()\n",
    "                    if k not in ignore_layers}\n",
    "    if hasattr(model, 'module'):\n",
    "        dummy_dict = model.module.state_dict()\n",
    "        dummy_dict.update(model_dict)\n",
    "    else:\n",
    "        dummy_dict = model.state_dict()\n",
    "        dummy_dict.update(model_dict)\n",
    "    model_dict = dummy_dict\n",
    "\n",
    "if hasattr(model, 'module'):\n",
    "    model.module.load_state_dict(model_dict, strict=False)\n",
    "else:\n",
    "    model.load_state_dict(model_dict, strict=False)\n",
    "return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = utils.warm_start_model(\n",
    "            hps.train.warm_start_checkpoint, generator, hps.train.ignored_layer\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(\"filelists/combine_audio_sid_text_test_filelist.txt\", \"r\") as txt_file:\n",
    "    lines = txt_file.readlines()\n",
    "    for line in lines:\n",
    "        audiopath = line.split(\"|\")[0]\n",
    "        if not os.path.isfile(audiopath):\n",
    "            print(audiopath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text import text_to_sequence, cmudict\n",
    "from text import cleaners\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_stn = \"Hello my name is Pras\"\n",
    "tst_stn = \"周末的我，只忙着陪你。\"\n",
    "\n",
    "tst_stn = \" \" + tst_stn.strip() + \" \"\n",
    "text_norm = text_to_sequence(tst_stn.strip(), ['basic_cleaners'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_to_sequence(tst_stn.strip(), ['universal_cleaners']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_to_sequence(unidecode(tst_stn).strip(), ['basic_cleaners']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Zhou Mo De Wo ,Zhi Mang Zhao Pei Ni .  '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unidecode(tst_stn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xi ndemoraetanarananiyoridesu'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unidecode(\"喜んでもらえたならなによりです\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = english_cleaners(tst_stn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_text(text, cleaner_names):\n",
    "  for name in cleaner_names:\n",
    "    cleaner = getattr(cleaners, name)\n",
    "    if not cleaner:\n",
    "      raise Exception('Unknown cleaner: %s' % name)\n",
    "    text = cleaner(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60,\n",
       " 52,\n",
       " 11,\n",
       " 61,\n",
       " 46,\n",
       " 11,\n",
       " 45,\n",
       " 58,\n",
       " 38,\n",
       " 51,\n",
       " 11,\n",
       " 39,\n",
       " 42,\n",
       " 46,\n",
       " 11,\n",
       " 47,\n",
       " 46,\n",
       " 51,\n",
       " 44,\n",
       " 11,\n",
       " 45,\n",
       " 58,\n",
       " 38,\n",
       " 51,\n",
       " 11,\n",
       " 62,\n",
       " 46,\n",
       " 51,\n",
       " 44,\n",
       " 11,\n",
       " 51,\n",
       " 46,\n",
       " 11,\n",
       " 7,\n",
       " 11]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
